# Natural Language Processing (NLP)

### **What is NLP?**

NLP is a field of CS and subfield of AI that aims to make computers understand human language. NLP uses computational linguistics (study of how language works) and various statistics, machine learning, and deep learning based models.
These technologies allow computers to analyze and process text or voice data, and to grasp their full meaning, including the speaker's or writer's intentions and emotions.
NLP powers many applications that use language, such as text translation, voice recognition. text summarisation. and chatbots.

### **Roadmap of Natural Language Processing**

#### **1️⃣ Text Preprocessing**

- Cleaning the input text
- Includes techniques like Tokenization, lemmatization, and Stemming

#### **2️⃣ Text Preprocessing 2**

- Converting input text to vectors
- Bag of Words (BOW), TF-IDF, unigrams, bigrams

#### **3️⃣ Text Preprocessing 3**

- Converting input text to vectors, but with advanced techniques
- Word2Vec, AvgWord2Vec

#### **4️⃣ RNN, LSTM RNN, GRU RNN**

- Deep Learning based techniques for NLP

#### **5️⃣ Text Preprocessing 4**

- Using Word Embedding to convert input text to vectors

#### **6️⃣ Transformers**

- Transformer is a neural network architecture used for performing machine learning tasks particularly in natural language processing (NLP)

#### **7️⃣ BERT (Bidirectional Encoder Representations from Transformers)**

- Powerful NLP model developed by Google that excels at understanding context by analyzing relationships between words in a sentence bidirectionally, revolutionizing various NLP tasks

### **Practical use cases of NLP**
